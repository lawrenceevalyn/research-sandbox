{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf400
{\fonttbl\f0\fnil\fcharset0 Georgia;}
{\colortbl;\red255\green255\blue255;\red236\green184\blue255;}
{\*\expandedcolortbl;;\cssrgb\c94500\c78400\c100000;}
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\sl312\slmult1\pardirnatural\partightenfactor0

\f0\fs22 \cf0 \cb2 [The other thing we learned from the classifier is that it is tantalizingly tempting to continue onward with someone else\'92s implicit bias.] [Frank was (marginally) more accurate because his \'93capta\'94 were captured in a way that was implicitly shaped by his knowledge of authorial gender \'97 which creates a classifier that will do better on its tests, but which can\'92t handle new information that is captured without Frank\'92s specific, individual, implicit {\field{\*\fldinst{HYPERLINK "scrivcmt://5296DAF4-13FA-431B-84E6-FACEEA76DC19"}}{\fldrslt bias.]}}\cb1   \cb2 [Other scholars have written a lot about this: machine learning mostly replicates the bias of the input. An algorithm to identify who to hire at Amazon, for example, will make its decisions based on who 
\i \cb2 has been
\i0 \cb2  hired, not who 
\i \cb2 should
\i0 \cb2  have been hired; because women are underrepresented in the pool of current employees, eliminating women from consideration will be an efficient way for the algorithm to zero on in the candidates with the highest certainty of being {\field{\*\fldinst{HYPERLINK "scrivcmt://52705FD1-1288-466D-99AE-7D0168E7CD2C"}}{\fldrslt \cb2 hired.}} Rather than \'91objectively\'92 eliminating hiring bias, therefore, it reinforces it. Even if it is not provided direct data regarding gender, it will find ways to infer [gender information, from names, women-only groups, women-only colleges]{\field{\*\fldinst{HYPERLINK "scrivcmt://9A36D420-D4CA-4808-860A-E5D04C923B28"}}{\fldrslt ][In}} the case of this project,]\cb1  if \'93sentimental\'94 is\cb2  [a female-coded term / code word for \'93female\'94], \cb1 the classifier will \cb2 [seize/expand/extrapolate from] \cb1 that implicit bias and perpetuate it. Revisiting Frank\'92s terminology with an eye for these coded shades of difference the interpretive multiplicity which earlier \cb2 [seemed like a critical strength] \cb1 now seem like a barrier to\cb2  [ongoing/extensible study]. \cb1 What makes one work \'93polemical\'94 and another \'93didactic\'94, other than the fact that men are much more likely to be \'93polemical\'94?\cb2  [These boundaries are so slippery that they can\'92t be replicated; the distinction is in connotation] [TODO: several more examples of Frank\'92s gendered terminology]  \cb1 His \'93capta\'94 are captured too \cb2 implicitly/subjectively\cb1 , so they are best able to tell us \'93did Frank think this author\'92s gender played a role in their decisions when he described their genre?\'94}